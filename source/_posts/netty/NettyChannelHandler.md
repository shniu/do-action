---
title: Netty 实战 - Pipeline 和 ChannelHandler
p: netty/NettyChannelHandler
date: 2019-05-18 20:31:45
tags:
---

Netty 内置了很多开箱即用的 channel handler，能很大程度上简化和节约编程。

### Pipeline

Netty 的 Pipeline 是 `ChannelPipeline`, 每个Channel都绑定一个 `ChannelPipeline`，它的实现原理是基于拦截过滤器模式。

> Intercepting Filter Pattern
> 参考：https://www.oracle.com/technetwork/java/interceptingfilter-142169.html
> 使用一种无需修改核心请求处理代码的标准方式来创建可插拔的过滤器来处理通用服务。过滤器拦截进入的请求和返回的响应，同时允许预处理和后置处理。我们可以很容易的添加或删除这些过滤器，不需要修改已有的代码。

### ChannelInboundHandlerAdapter

这个适配器主要实现了 `ChannelInboundHandler` 的所有方法。

### ChannelOutboundHandlerAdapter

### TCP 中拆包和粘包的处理

为什么会出现拆包和粘包？（why）
TCP 是一个“流式”协议，在OS的底层，是源源不断的将二进制数据流发送出去，应用程序将用户空间的数据写到Socket的写缓冲取，网卡从写缓冲区中读取数据将二进制数据简单处理后打包发送出去，所以可见，TCP 协议并不会关心业务数据的含义，它会根据发送时的实际情况将数据进行拆包或者粘包处理，然后发送，主要会有以下表现：
1. 正常的将两个包，按照两次独立的包发送出去，这样刚刚好
2. 将两个或多个数据包，放在一起发送出去
3. 将一个数据包拆成很多包发送出去
4. 将一个数据包的一部分粘合另外一个数据包发送出去

出现的本质原因是：
1. 应用程序write写入的字节大小大于套接口发送缓冲区大小；
2. 进行MSS（最大报文长度）大小的TCP分段
3. 以太网帧的payload大于MTU进行IP分片

处理办法：（how）
底层TCP协议无法理解上层的业务数据，所以只能通过上层的应用协议设计来解决，一般有如下解决方法
1. 消息定长，例如每个报文的大小为固定长度200字节，如果不够，空位补空格
2. 在包尾增加回车换行符进行分割
3. 将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段，通常设计思路为消息头的第一个字段使用int32来表示消息的总长度

一般情况下发送端发来的数据都是自动做拆包粘包的，所以接收端接受数据时要做拆包处理，基本思路是不断从 TCP 缓冲区中读取数据，每次读取完都需要判断是否是一个完整的数据包
1. 如果当前读取的数据不足以拼接成一个完整的业务数据包，那就保留该数据，继续从 TCP 缓冲区中读取数据，直到拼接成一个完整的业务包
2. 如果当前读取的数据已经能拼接出一个业务包，那就将已经读取的数据包拼接上本次读取的数据包，拼接成业务包，然后剩下的数据保留，尝试和下次读取的数据进行拼接处理

可见，对于以上过程实现起来还是相对麻烦的，需要设计协议、需要做拆包粘包处理、需要考虑异常等，但是 Netty 提供了几个内置的拆包器，在很大程度上能够满足我们的需要。

#### ByteToMessageDecoder

![Decoder](/images/FixedLengthFrameDecoder.png)


